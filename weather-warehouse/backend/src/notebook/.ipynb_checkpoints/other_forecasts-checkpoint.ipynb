{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ed97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "location_name = \"Tokyo\"\n",
    "country = \"JP\"\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "seq_length = 30\n",
    "forecast_days = 7\n",
    "\n",
    "# Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "\n",
    "print(f\"Starting forecast process for location: {location_name}, country: {country}\")\n",
    "\n",
    "# Function to query single-day historical data\n",
    "def useHistoricalDataQuery(location_name, country, date):\n",
    "    print(f\"Querying historical data for {location_name}, {country} on {date}...\")\n",
    "    api_url = \"http://127.0.0.1:4000/historical/historicalData\"\n",
    "    payload = {\n",
    "        \"location\": {\"name\": location_name, \"country\": country},\n",
    "        \"date\": date\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        historical_data = response.json()\n",
    "        print(f\"Data for {date} received.\")\n",
    "        return pd.DataFrame(historical_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling historicalData API for {date}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Generate forecast using same date from previous years\n",
    "def forecast_from_past_same_days(location_name, country, forecast_days):\n",
    "    today = datetime.today()\n",
    "    forecast_output = []\n",
    "    for i in range(1, forecast_days + 1):\n",
    "        target_date = today + pd.Timedelta(days=i)\n",
    "        month_day = target_date.strftime('%m-%d')\n",
    "        print(f\"Looking up past temperatures for {month_day}...\")\n",
    "        temps = []\n",
    "        for year in range(2010, 2024):\n",
    "            past_date = f\"{year}-{month_day}\"\n",
    "            df = useHistoricalDataQuery(location_name, country, past_date)\n",
    "            if not df.empty and 'Temperature' in df.columns:\n",
    "                temps.extend(df['Temperature'].values.tolist())\n",
    "        if temps:\n",
    "            avg_temp = round(float(np.mean(temps)), 2)\n",
    "            forecast_output.append({\"date\": str(target_date.date()), \"Temperature\": avg_temp})\n",
    "        else:\n",
    "            print(f\"No data found for {month_day} across years.\")\n",
    "            forecast_output.append({\"date\": str(target_date.date()), \"Temperature\": None})\n",
    "    return forecast_output\n",
    "\n",
    "# Run the same-day-from-past-years forecast\n",
    "forecast_output = forecast_from_past_same_days(location_name, country, forecast_days)\n",
    "\n",
    "print(\"\\n7-Day Temperature Forecast (Based on Same Date in Past Years):\")\n",
    "for entry in forecast_output:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c815b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "location_name = \"Tokyo\"\n",
    "country = \"JP\"\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2010-01-10\"\n",
    "seq_length = 30\n",
    "forecast_days = 7\n",
    "\n",
    "# Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "\n",
    "print(f\"Starting multivariate LSTM forecast for location: {location_name}, country: {country}\")\n",
    "\n",
    "# Function to query full historical daily data\n",
    "def useHistoricalDataQuery(location_name, country, date):\n",
    "    print(f\"Querying historical data for {location_name}, {country} on {date}...\")\n",
    "    api_url = \"http://127.0.0.1:4000/historical/historicalData\"\n",
    "    payload = {\n",
    "        \"location\": {\"name\": location_name, \"country\": country},\n",
    "        \"date\": date\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        historical_data = response.json()\n",
    "        print(f\"Data for {date} received.\")\n",
    "        return pd.DataFrame(historical_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling historicalData API for {date}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Collect data across a range of dates\n",
    "def collect_full_data(start_year, end_year):\n",
    "    all_data = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            for day in [1, 10, 20]:  # To reduce API load; ideally use full daily data\n",
    "                date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "                df = useHistoricalDataQuery(location_name, country, date_str)\n",
    "                if not df.empty:\n",
    "                    all_data.append(df)\n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "print(\"Collecting historical weather data...\")\n",
    "data = collect_full_data(2010, 2023)\n",
    "\n",
    "# Filter and sort\n",
    "features = ['Temperature', 'MinTemperature', 'MaxTemperature', 'WindSpeed', 'Precipitation', 'Pressure']\n",
    "data = data.dropna(subset=features)\n",
    "data = data.sort_values(by='Date')\n",
    "\n",
    "print(f\"Collected {len(data)} rows of historical data.\")\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data[features])\n",
    "\n",
    "# Prepare sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length, 0])  # Target is average temperature\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x, y = create_sequences(scaled_data, seq_length)\n",
    "x = x.reshape((x.shape[0], x.shape[1], len(features)))\n",
    "\n",
    "print(f\"Input shape: {x.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "# Build the LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(seq_length, len(features))))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "model.fit(x, y, epochs=10, batch_size=16, verbose=1)\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Forecast future temperatures\n",
    "print(\"Generating forecast for next 7 days...\")\n",
    "last_seq = scaled_data[-seq_length:]\n",
    "input_seq = last_seq.copy()\n",
    "forecast_scaled = []\n",
    "\n",
    "for i in range(forecast_days):\n",
    "    pred = model.predict(input_seq.reshape(1, seq_length, len(features)), verbose=0)\n",
    "    forecast_scaled.append(pred[0, 0])\n",
    "    next_input = input_seq[1:].copy()\n",
    "    next_input = np.vstack([next_input, np.concatenate([[pred[0, 0]], input_seq[-1, 1:]])])\n",
    "    input_seq = next_input\n",
    "\n",
    "# Inverse transform the predicted temperatures\n",
    "reconstructed = np.zeros((forecast_days, len(features)))\n",
    "reconstructed[:, 0] = forecast_scaled\n",
    "forecast = scaler.inverse_transform(reconstructed)[:, 0]\n",
    "\n",
    "# Generate forecast dates\n",
    "start_date = pd.to_datetime(datetime.today().strftime('%Y-%m-%d'))\n",
    "forecast_dates = pd.date_range(start=start_date + pd.Timedelta(days=1), periods=forecast_days)\n",
    "forecast_output = [{\"date\": str(date.date()), \"Temperature\": round(temp, 2)} for date, temp in zip(forecast_dates, forecast)]\n",
    "\n",
    "print(\"\\n7-Day LSTM Temperature Forecast:\")\n",
    "for entry in forecast_output:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "location_name = \"Tokyo\"\n",
    "country = \"JP\"\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2010-01-31\"\n",
    "seq_length = 30\n",
    "forecast_days = 7\n",
    "\n",
    "# Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "\n",
    "print(f\"Starting forecast process for location: {location_name}, country: {country}\")\n",
    "\n",
    "# Function to query single-day historical data\n",
    "def useHistoricalDataQuery(location_name, country, date):\n",
    "    print(f\"Querying historical data for {location_name}, {country} on {date}...\")\n",
    "    api_url = \"http://127.0.0.1:4000/historical/historicalData\"\n",
    "    payload = {\n",
    "        \"location\": {\"name\": location_name, \"country\": country},\n",
    "        \"date\": date\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        historical_data = response.json()\n",
    "        print(f\"Data for {date} received.\")\n",
    "        return pd.DataFrame(historical_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling historicalData API for {date}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to fetch multi-year data\n",
    "def fetch_multiple_years_of_data(location_name, country, start_date, end_date):\n",
    "    print(f\"Fetching data from {start_date} to {end_date} for {location_name}, {country}\")\n",
    "    all_data = []\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    for date in date_range:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        df = useHistoricalDataQuery(location_name, country, date_str)\n",
    "        if not df.empty:\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"No data for {date_str}\")\n",
    "    if all_data:\n",
    "        combined = pd.concat(all_data).drop_duplicates().reset_index(drop=True)\n",
    "        print(f\"Total records fetched: {len(combined)}\")\n",
    "        return combined\n",
    "    else:\n",
    "        print(\"No historical data retrieved.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch historical data\n",
    "print(\"Fetching historical weather data...\")\n",
    "historical_df = fetch_multiple_years_of_data(location_name, country, start_date, end_date)\n",
    "if historical_df.empty or 'Temperature' not in historical_df.columns:\n",
    "    raise ValueError(\"No valid historical data returned.\")\n",
    "\n",
    "# Preprocessing\n",
    "print(\"Starting data preprocessing...\")\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(historical_df[['Temperature']])\n",
    "print(\"Data scaled using MinMaxScaler.\")\n",
    "\n",
    "# Create sequences\n",
    "print(\"Creating sequences for training...\")\n",
    "def create_sequences(data, seq_length):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    print(f\"Total sequences created: {len(x)}\")\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x, y = create_sequences(scaled_data, seq_length)\n",
    "x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "print(f\"Input shape: {x.shape}, Output shape: {y.shape}\")\n",
    "\n",
    "# Build model\n",
    "print(\"Building LSTM model...\")\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(seq_length, 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(\"Model built and compiled.\")\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "model.fit(x, y, epochs=10, batch_size=16, verbose=1)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Forecast\n",
    "print(f\"Forecasting next {forecast_days} days...\")\n",
    "input_seq = scaled_data[-seq_length:]\n",
    "forecast = []\n",
    "for i in range(forecast_days):\n",
    "    print(f\"Generating forecast for day {i+1}...\")\n",
    "    pred = model.predict(input_seq.reshape(1, seq_length, 1), verbose=0)\n",
    "    forecast.append(pred[0, 0])\n",
    "    input_seq = np.append(input_seq[1:], pred).reshape(seq_length, 1)\n",
    "\n",
    "# Inverse transform\n",
    "print(\"Inverse scaling forecast data...\")\n",
    "forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Output\n",
    "print(\"Preparing forecast output...\")\n",
    "forecast_dates = pd.date_range(start=pd.to_datetime(datetime.today()) + pd.Timedelta(days=1), periods=forecast_days)\n",
    "forecast_output = [{\"date\": str(d.date()), \"Temperature\": round(float(t), 2)} for d, t in zip(forecast_dates, forecast)]\n",
    "\n",
    "print(\"\\n7-Day Temperature Forecast:\")\n",
    "for entry in forecast_output:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03309ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "location_name = \"Tokyo\"\n",
    "country = \"JP\"\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2010-01-31\"\n",
    "seq_length = 30\n",
    "forecast_days = 7\n",
    "\n",
    "# Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "\n",
    "print(f\"Starting forecast process for location: {location_name}, country: {country}\")\n",
    "\n",
    "# Function to query single-day historical data\n",
    "def useHistoricalDataQuery(location_name, country, date):\n",
    "    print(f\"Querying historical data for {location_name}, {country} on {date}...\")\n",
    "    api_url = \"http://127.0.0.1:4000/historical/historicalData\"\n",
    "    payload = {\n",
    "        \"location\": {\"name\": location_name, \"country\": country},\n",
    "        \"date\": date\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        historical_data = response.json()\n",
    "        print(f\"Data for {date} received.\")\n",
    "        return pd.DataFrame(historical_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling historicalData API for {date}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to fetch multi-year data\n",
    "def fetch_multiple_years_of_data(location_name, country, start_date, end_date):\n",
    "    print(f\"Fetching data from {start_date} to {end_date} for {location_name}, {country}\")\n",
    "    all_data = []\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    for date in date_range:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        df = useHistoricalDataQuery(location_name, country, date_str)\n",
    "        if not df.empty:\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"No data for {date_str}\")\n",
    "    if all_data:\n",
    "        combined = pd.concat(all_data).drop_duplicates().reset_index(drop=True)\n",
    "        print(f\"Total records fetched: {len(combined)}\")\n",
    "        return combined\n",
    "    else:\n",
    "        print(\"No historical data retrieved.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch historical data\n",
    "print(\"Fetching historical weather data...\")\n",
    "historical_df = fetch_multiple_years_of_data(location_name, country, start_date, end_date)\n",
    "if historical_df.empty or 'Temperature' not in historical_df.columns:\n",
    "    raise ValueError(\"No valid historical data returned.\")\n",
    "\n",
    "# Preprocessing\n",
    "print(\"Starting data preprocessing...\")\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(historical_df[['Temperature']])\n",
    "print(\"Data scaled using MinMaxScaler.\")\n",
    "\n",
    "# Create sequences\n",
    "print(\"Creating sequences for training...\")\n",
    "def create_sequences(data, seq_length):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    print(f\"Total sequences created: {len(x)}\")\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x, y = create_sequences(scaled_data, seq_length)\n",
    "x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "print(f\"Input shape: {x.shape}, Output shape: {y.shape}\")\n",
    "\n",
    "# Build model\n",
    "print(\"Building LSTM model...\")\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(seq_length, 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(\"Model built and compiled.\")\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "model.fit(x, y, epochs=10, batch_size=16, verbose=1)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Forecast\n",
    "print(f\"Forecasting next {forecast_days} days...\")\n",
    "input_seq = scaled_data[-seq_length:]\n",
    "forecast = []\n",
    "for i in range(forecast_days):\n",
    "    print(f\"Generating forecast for day {i+1}...\")\n",
    "    pred = model.predict(input_seq.reshape(1, seq_length, 1), verbose=0)\n",
    "    forecast.append(pred[0, 0])\n",
    "    input_seq = np.append(input_seq[1:], pred).reshape(seq_length, 1)\n",
    "\n",
    "# Inverse transform\n",
    "print(\"Inverse scaling forecast data...\")\n",
    "forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Output\n",
    "print(\"Preparing forecast output...\")\n",
    "forecast_dates = pd.date_range(start=pd.to_datetime(datetime.today()) + pd.Timedelta(days=1), periods=forecast_days)\n",
    "forecast_output = [{\"date\": str(d.date()), \"Temperature\": round(float(t), 2)} for d, t in zip(forecast_dates, forecast)]\n",
    "\n",
    "print(\"\\n7-Day Temperature Forecast:\")\n",
    "for entry in forecast_output:\n",
    "    print(entry)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
