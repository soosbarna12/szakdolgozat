{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7c8d22",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting forecast process for Location: Tokyo, Date: 2025-05-08 00:00:00\n",
      "No null bytes found.\n",
      "Fetching historical data for location: Tokyo, country: JP, date: 2016-01-01\n",
      "Historical data fetched successfully.\n",
      "   WeatherID  LocationKey   DateKey                  FullDate CityName  \\\n",
      "0  194828537         5472  20160101  2016-01-01T00:00:00.000Z    Tokyo   \n",
      "\n",
      "  CountryCode  Temperature  MinTemperature  MaxTemperature Humidity  \\\n",
      "0          JP          7.3             3.9            12.1     None   \n",
      "\n",
      "   WindSpeed  Precipitation  Pressure CloudCover     Source  \\\n",
      "0        9.6              0    1025.2       None  Meteostat   \n",
      "\n",
      "            ObservationTime  \n",
      "0  2016-01-01T00:00:00.000Z  \n",
      "-------------------------------------------------\n",
      "   WeatherID  LocationKey   DateKey                  FullDate CityName  \\\n",
      "0  194828537         5472  20160101  2016-01-01T00:00:00.000Z    Tokyo   \n",
      "\n",
      "  CountryCode  Temperature  MinTemperature  MaxTemperature Humidity  \\\n",
      "0          JP          7.3             3.9            12.1     None   \n",
      "\n",
      "   WindSpeed  Precipitation  Pressure CloudCover     Source  \\\n",
      "0        9.6              0    1025.2       None  Meteostat   \n",
      "\n",
      "            ObservationTime  \n",
      "0  2016-01-01T00:00:00.000Z  \n",
      "Starting data preprocessing...\n",
      "Scaled data (first 5 rows):\n",
      "[[0.]]\n",
      "Creating sequences with sequence length: 30\n",
      "Created 0 sequences.\n",
      "Input shape: (0,), Output shape: (0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Reshape for LSTM\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshaped input for LSTM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Step 3: Build LSTM model\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "location = \"Tokyo\"\n",
    "date = \"2025-05-07\"  # This will be overridden by papermill\n",
    "\n",
    "# Ensure the date is in YYYY-MM-DD format\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "\n",
    "\n",
    "date = pd.to_datetime(datetime.today().strftime('%Y-%m-%d'))\n",
    "sys.stdout.write(f\"Starting forecast process for Location: {location}, Date: {date}\\n\")\n",
    "\n",
    "\n",
    "with open(\"D:\\\\Documents\\\\OE\\\\Szakdolgozat\\\\szakdolgozat\\\\weather-warehouse\\\\backend\\\\src\\\\notebooks\\\\lstm_forecast.ipynb\", \"rb\") as f:\n",
    "    content = f.read()\n",
    "    if b\"\\x00\" in content:\n",
    "        print(\"Null bytes found in the file!\")\n",
    "    else:\n",
    "        print(\"No null bytes found.\")\n",
    "        \n",
    "\n",
    "# Step 1: Query historical data\n",
    "def useHistoricalDataQuery(location_name, country, date):\n",
    "    print(f\"Fetching historical data for location: {location_name}, country: {country}, date: {date}\")\n",
    "    api_url = \"http://127.0.0.1:4000/historical/historicalData\"\n",
    "    payload = {\n",
    "        \"location\": {\"name\": location_name, \"country\": country},\n",
    "        \"date\": date\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        historical_data = response.json()\n",
    "        print(\"Historical data fetched successfully.\")\n",
    "        return pd.DataFrame(historical_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling historicalData API: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame on error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "location_name = \"Tokyo\"\n",
    "country = \"JP\"\n",
    "date = \"2016-01-01\"\n",
    "data = useHistoricalDataQuery(location_name, country, date)\n",
    "print(data.head())\n",
    "print(\"-------------------------------------------------\")\n",
    "print(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Preprocess data\n",
    "print(\"Starting data preprocessing...\")\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data[['Temperature']])\n",
    "print(f\"Scaled data (first 5 rows):\\n{scaled_data[:5]}\")\n",
    "\n",
    "# Prepare sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    print(f\"Creating sequences with sequence length: {seq_length}\")\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    print(f\"Created {len(x)} sequences.\")\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "seq_length = 30\n",
    "x, y = create_sequences(scaled_data, seq_length)\n",
    "print(f\"Input shape: {x.shape}, Output shape: {y.shape}\")\n",
    "\n",
    "# Reshape for LSTM\n",
    "x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "print(f\"Reshaped input for LSTM: {x.shape}\")\n",
    "\n",
    "# Step 3: Build LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(seq_length, 1)))  # Explicitly define the input shape\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(\"LSTM model built successfully.\")\n",
    "\n",
    "# Step 4: Train model\n",
    "print(\"Training LSTM model...\")\n",
    "model.fit(x, y, epochs=10, batch_size=16, verbose=1)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Step 5: Predict next 7 days\n",
    "print(\"Generating forecast for the next 7 days...\")\n",
    "last_seq = scaled_data[-seq_length:]\n",
    "forecast = []\n",
    "input_seq = last_seq.copy()\n",
    "\n",
    "for i in range(7):\n",
    "    pred = model.predict(input_seq.reshape(1, seq_length, 1))\n",
    "    forecast.append(pred[0, 0])\n",
    "    input_seq = np.append(input_seq[1:], pred).reshape(seq_length, 1)\n",
    "    print(f\"Day {i+1} forecast: {forecast[-1]}\")\n",
    "\n",
    "# Inverse scale\n",
    "forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
    "print(f\"Forecast after inverse scaling: {forecast}\")\n",
    "\n",
    "# Output forecast values\n",
    "forecast_dates = pd.date_range(start=date + pd.Timedelta(days=1), periods=7)\n",
    "forecast_data = [{\"date\": str(d.date()), \"Temperature\": float(f)} for d, f in zip(forecast_dates, forecast)]\n",
    "print(\"Final forecast data:\")\n",
    "for entry in forecast_data:\n",
    "    print(entry)\n",
    "\n",
    "# Explicitly output the forecast data\n",
    "forecast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a9999-dac0-451e-ac52-77b48508242f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
